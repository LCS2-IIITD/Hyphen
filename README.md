# Hyphen

Implementation of [Public Wisdom Matters! Discourse-Aware Hyperbolic Fourier Co-Attention for Social-Text Classification](https://arxiv.org/abs/2209.13017), accepted at NeurIPS 2022, as an Oral (Spotlight) paper. 

<p align="center">
  <img width="600px" src="img/model.png" >
</p>

## Custom dataset processing
Generate the Abstract Meaning Representations for all user comments in a dataset:
```python
CUDA_VISIBLE_DEVICES=2 python3 amr/amr_gen.py --dataset politifact --max-comments 50
```

Modify attributes and instances variable names across all AMRs.
```python
python3 amr/amr_var.py --dataset politifact
```

Coreference resolution.
```python
python3 amr/amr_coref/amr_coref.py --dataset politifact
```

Adding the dummy node, and egdes and final step in merging AMRs to form macro-AMR.
```python
python3 amr/amr_dummy.py --dataset politifact
```

Convert the generated macro-amr to subgraphs in DGL format
```python
python3 amr/amr_dgl.py --dataset politifact --test-split 0.1
```
## Run

```python
CUDA_VISIBLE_DEVICES=2 python3 run.py --manifold PoincareBall --lr 0.001 --dataset politifact  --batch-size 32 --epochs 5 --max-sents 20 --max-coms 10 --max-com-len 10 --max-sent-len 10 --log-path logging/run
```

To run `Hyphen-euclidean`, use the following script:

```python
CUDA_VISIBLE_DEVICES=2 python3 run.py --manifold Euclidean --lr 0.001 --dataset politifact  --batch-size 32 --epochs 5 --max-sents 20 --max-coms 10 --max-com-len 10 --max-sent-len 10 --log-path logging/run
```

To run `Hyphen-euclidean w/o Fourier`, use the following script:

```python
CUDA_VISIBLE_DEVICES=2 python3 run.py --no-fourier --manifold Euclidean --lr 0.001 --dataset politifact  --batch-size 32 --epochs 5 --max-sents 20 --max-coms 10 --max-com-len 10 --max-sent-len 10 --log-path logging/run
```

To run `Hyphen-euclidean w/o Comments`, use the following script:

```python
CUDA_VISIBLE_DEVICES=2 python3 run.py --no-comments --manifold Euclidean --lr 0.001 --dataset politifact  --batch-size 32 --epochs 5 --max-sents 20 --max-coms 10 --max-com-len 10 --max-sent-len 10 --log-path logging/run
```
To run `Hyphen-euclidean w/o Content`, use the following script:

```python
CUDA_VISIBLE_DEVICES=2 python3 run.py --no-content --manifold Euclidean --lr 0.001 --dataset politifact  --batch-size 32 --epochs 5 --max-sents 20 --max-coms 10 --max-com-len 10 --max-sent-len 10 --log-path logging/run
```
## üìö Sentence-level Fact-checked Annotated dataset
### Hyphen fine-grained explainability - Annotated dataset *release*! üíø
 
We hereby release the annotated Politifact dataset. The dataset is present [here](annotation). Find more details about the released dataset, format and the annotation details in the [ReadMe](annotation/annotation.md) file. 

**Abstract**: Fake news üì∞ is often generated by **manipulating only a small part of the true information** i.e. entities, relations, small parts of a sentence, or a paragraph. It is possible that certain true information is also present in the news piece to make it more appealing to the public, and thus it is crucial to distinguish between true and/or fake parts of a piece of information. Thus, we utilise and release a **sentence-level fact-checked annotated dataset**. We annotate the **Politifact** dataset with ground truth evidence corresponding to different parts of the news text, by referring to fact-checking websites [Politifact](https://www.politifact.com/) and [Gossipcop](https://www.snopes.com/), and other trustable online sources. 

## ‚úèÔ∏è Citation

If you think that this work is helpful, please feel free to leave a star ‚≠êÔ∏è and cite our paper:

```
@article{grover2022public,
  title={Public Wisdom Matters! Discourse-Aware Hyperbolic Fourier Co-Attention for Social-Text Classification},
  author={Grover, Karish and Angara, SM and Akhtar, Md and Chakraborty, Tanmoy and others},
  journal={arXiv preprint arXiv:2209.13017},
  year={2022}
}
```